![present](https://user-images.githubusercontent.com/67382222/112210161-a62df480-8c1a-11eb-835b-ea480b280864.JPG)


## Presentation EarComp â€˜19, 1st International Workshop on earable computing, London, UK
![arm1](https://user-images.githubusercontent.com/67382222/112209554-e345b700-8c19-11eb-839c-525f11e84663.JPG)
![arm2](https://user-images.githubusercontent.com/67382222/112209560-e50f7a80-8c19-11eb-8b70-0f198c337df2.JPG)
![arm3](https://user-images.githubusercontent.com/67382222/112209579-e9d42e80-8c19-11eb-8cd1-2d1a2c81afe1.JPG)
![arm4](https://user-images.githubusercontent.com/67382222/112209585-eb055b80-8c19-11eb-9e71-be7c6a32bb76.JPG)
![arm5](https://user-images.githubusercontent.com/67382222/112209594-ed67b580-8c19-11eb-899b-54977b934d6f.JPG)







Head motion-based interfaces for controlling robot arms in
real time have been presented in both medical-oriented research as well as human-robot interaction. We present an
especially minimal and low-cost solution that uses the eSense [1] ear-worn prototype as a small head-worn controller,
enabling direct control of an inexpensive robot arm in the
environment. We report on the hardware and software setup,
as well as the experiment design and early results

* 3-DOF robot arm
* Bluetooth Low Energy(BLE)
* ESP32-WROOM-32D
* IMU (Inertial Measurement Unit)
* Frame transformation
* Sensor fusion with complementary filter 
* mg996r servo motors
* Paper https://doi.org/10.1145/3345615.3361138